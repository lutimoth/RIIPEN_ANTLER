{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of OpenCV + MobileNet for video analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-28T05:30:01.317777Z",
     "iopub.status.busy": "2021-03-28T05:30:01.317479Z",
     "iopub.status.idle": "2021-03-28T05:30:02.549704Z",
     "shell.execute_reply": "2021-03-28T05:30:02.549282Z",
     "shell.execute_reply.started": "2021-03-28T05:30:01.317712Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RUN_NAME = '20230120 - arch=mobilenet_v2_fpn - samples=7500 frozen=1 epochs=10 bs=48 res=380 _data=external'\n",
    "\n",
    "SAVE_IMAGES_TO_FILE = False  # flag if we want to capture the image to disk\n",
    "\n",
    "SYMBOL = None\n",
    "\n",
    "RESOLUTION = 300\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "                         \n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "from IPython.display import Video, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-28T05:30:01.317777Z",
     "iopub.status.busy": "2021-03-28T05:30:01.317479Z",
     "iopub.status.idle": "2021-03-28T05:30:02.549704Z",
     "shell.execute_reply": "2021-03-28T05:30:02.549282Z",
     "shell.execute_reply.started": "2021-03-28T05:30:01.317712Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Springboard_GIT\\\\RIIPEN_ANTLER\\\\Pool_Drowning_Detection\\\\Tim Notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done! Took 14.159499645233154 seconds\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_SAVED_MODEL = \"./Tensorflow/workspace/second_training/exported_models/my_mobilenet320_fpn/saved_model\"\n",
    "\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-25T22:20:59.177139Z",
     "iopub.status.busy": "2021-03-25T22:20:59.177035Z",
     "iopub.status.idle": "2021-03-25T22:20:59.178986Z",
     "shell.execute_reply": "2021-03-25T22:20:59.178640Z",
     "shell.execute_reply.started": "2021-03-25T22:20:59.177129Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = \"./Tensorflow/workspace/second_training/annotations/label_map.pbtxt\"\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                   use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Springboard_GIT\\\\RIIPEN_ANTLER\\\\Pool_Drowning_Detection\\\\Tim Notebooks'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\Pool Videos\\\\notdrowning'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.relpath('E:\\\\Springboard_GIT\\\\RIIPEN_ANTLER\\\\Pool_Drowning_Detection\\\\Pool Videos\\\\notdrowning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Pool Videos\\notdrowning\\notdrowning18.avi\n"
     ]
    }
   ],
   "source": [
    "NOTDROWNING_VIDEO_URL = \"..\\\\Pool Videos\\\\notdrowning\"\n",
    "\n",
    "video_url = NOTDROWNING_VIDEO_URL + '\\\\notdrowning18.avi'\n",
    "print(video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frac = 0.65  # scaling factor for display\n",
    "# display(\n",
    "#     Video(data=video_url, embed=True, height=int(720 * frac), \n",
    "#           width=int(1280 * frac))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-25T22:20:59.179703Z",
     "iopub.status.busy": "2021-03-25T22:20:59.179548Z",
     "iopub.status.idle": "2021-03-25T22:20:59.186611Z",
     "shell.execute_reply": "2021-03-25T22:20:59.185856Z",
     "shell.execute_reply.started": "2021-03-25T22:20:59.179687Z"
    }
   },
   "outputs": [],
   "source": [
    "def setup_camera() -> cv.VideoCapture:\n",
    "    '''\n",
    "    Set up the video source\n",
    "    '''\n",
    "    cap = cv.VideoCapture(video_url)  \n",
    "\n",
    "#     print(f'Autofocus status: {cap.set(cv.CAP_PROP_AUTOFOCUS, 0)}')\n",
    "#     print(f'Manual focus to shortest distance: {cap.set(cv.CAP_PROP_FOCUS, 0)}')\n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video stream or file!\")\n",
    "    \n",
    "    return cap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def close_camera():\n",
    "    '''\n",
    "    Close all capture devices and destroy open capture windows\n",
    "    '''\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def print_stats():\n",
    "    '''\n",
    "    Print some basic stats to stdout\n",
    "    '''\n",
    "    \n",
    "    print(f'Frame shape = {frame.shape}')\n",
    "    print(f'Total number of Frames = {nframe}')\n",
    "    print(f'Number of frames processed = {n_proc_frames // PROC_NTH_FRAME}')\n",
    "    \n",
    "    \n",
    "    \n",
    "# @TODO: Factor out the directory creation logic - slow/redundant    \n",
    "def save_images(frame, prframe):\n",
    "    '''\n",
    "    write small and large images to jpeg\n",
    "    '''\n",
    "    symbol_dir = SYMBOL\n",
    "    \n",
    "    #seperate the directory path\n",
    "    datadir_small = f'../data/{maindir}-S/{symbol_dir}'\n",
    "    datadir_large = f'../data/{maindir}-L/{symbol_dir}'\n",
    "\n",
    "    # build the entire directory structure if it doesn't exist\n",
    "    if not os.path.isdir(datadir_small):\n",
    "        os.makedirs(datadir_small)\n",
    "        \n",
    "    if not os.path.isdir(datadir_large):\n",
    "        os.makedirs(datadir_large)\n",
    "    \n",
    "    # create a directory+filename template\n",
    "    ftemplate_small = f'{datadir_small}/{file_prefix}-{n_save_frames}.jpg'\n",
    "    ftemplate_large = f'{datadir_large}/{file_prefix}-{n_save_frames}.jpg'\n",
    "    \n",
    "    # write the image to a file\n",
    "#     cv.imwrite(ftemplate_small, prframe)\n",
    "    cv.imwrite(ftemplate_large, frame)\n",
    "    \n",
    "    frame = cv.putText(frame, f'Saved Frame {SYMBOL} #{n_save_frames}', \n",
    "                   org=(20,40), fontFace=cv.FONT_HERSHEY_PLAIN, \n",
    "                   fontScale=2, color=(0,255,255), thickness=2,\n",
    "                   lineType=cv.LINE_AA) \n",
    "    \n",
    "    # Display the frame with the writing on it\n",
    "    cv.imshow('What the Camera Sees:',frame)\n",
    "    \n",
    "    \n",
    "    \n",
    "# def disable_progress():\n",
    "#     fastprogress.fastprogress.NO_BAR = True\n",
    "#     master_bar, progress_bar = fastprogress.fastprogress.force_console_behavior()\n",
    "# #     fastai.basic_train.master_bar, fastai.basic_train.progress_bar = master_bar, progress_bar\n",
    "    \n",
    "# # def enable_progress():\n",
    "# #     fastai.basic_train.master_bar, fastai.basic_train.progress_bar = fastprogress.master_bar, fastprogress.progress_bar\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Open the video camera, loop for every Frame, massage the image and make a prediction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the main code cel.  It has 2 purposes. When you hit the spacebar, it will either:\n",
    "1. Make an ASL alphabet translation or \n",
    "2. If SAVE_IMAGES_TO_FILE is True, it will save an image to the data dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-25T22:20:59.188695Z",
     "iopub.status.busy": "2021-03-25T22:20:59.188365Z",
     "iopub.status.idle": "2021-03-25T22:31:17.580937Z",
     "shell.execute_reply": "2021-03-25T22:31:17.580456Z",
     "shell.execute_reply.started": "2021-03-25T22:20:59.188657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't read frame from capture source!\n"
     ]
    }
   ],
   "source": [
    "# from fastai.vision  import *\n",
    "# import torch\n",
    "# import PIL\n",
    "\n",
    "PROC_NTH_FRAME = 5  # Skip every N-1 frames - increase this if your computer lags\n",
    "\n",
    "# maindir = 'frank-ledlights'  # these are image saving parameters dir/file\n",
    "# file_prefix = 'oldwebcam_leds'\n",
    "\n",
    "n_proc_frames, nframe = 0,0  # number of frames\n",
    "n_save_frames = 0  # number of captured frames for saving to file\n",
    "\n",
    "# declare here to widen scope\n",
    "pred, probs, pred_idx = [0], [0], 0\n",
    "frame, prframe = None, None\n",
    "\n",
    "if SAVE_IMAGES_TO_FILE:\n",
    "    SYMBOL = input('Enter Symbol of interest: ')[0]\n",
    "    \n",
    "cap = setup_camera()\n",
    "\n",
    "\n",
    "# \"Game\" Loop ... for every frame\n",
    "while(cap.isOpened()):\n",
    "    nframe += 1\n",
    "    ret, frame = cap.read()  # Capture frame\n",
    "    wait_ret = cv.waitKey(1)  # key char value if any\n",
    "\n",
    "    # Break out of the loop if the user presses 'Q'\n",
    "    if wait_ret & 0xFF == ord('q'):\n",
    "        print_stats()\n",
    "        break\n",
    "    \n",
    "    # only process the rest if the capture was successful\n",
    "    if not ret:\n",
    "        print(\"Can't read frame from capture source!\")\n",
    "        break  # break out of loop to let the camera close\n",
    "\n",
    "    # process only if the space key is hit and\n",
    "    # only process every PROC_NTH_FRAME frames \n",
    "    if (nframe % PROC_NTH_FRAME == 0):  # and wait_ret & 0xFF == ord(' ')  \n",
    "        n_proc_frames +=1  # num processed frames\n",
    "\n",
    "\n",
    "#         # this version for resnet34 w/ 300px image\n",
    "#         prframe = cv.resize(frame[:, 80:-80], (300, 300))\n",
    "        \n",
    "        # Display the frame that we pass through the predictor\n",
    "#         cv.imshow('What the Predictor Sees:', prframe)\n",
    "\n",
    "#         if SAVE_IMAGES_TO_FILE :\n",
    "#             if wait_ret & 0xFF == ord(' '):  # only save when pressing the spacebar\n",
    "#                 n_save_frames = n_save_frames + 1\n",
    "#                 save_images(frame, prframe)\n",
    "#             continue  # no need to predict\n",
    "    input_tensor = tf.convert_to_tensor(frame)\n",
    "    \n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "    \n",
    "\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                   for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    \n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "            \n",
    "#     image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          frame,\n",
    "          detections['detection_boxes'],\n",
    "          detections['detection_classes'],\n",
    "          detections['detection_scores'],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          min_score_thresh=.30,\n",
    "          agnostic_mode=False)\n",
    "\n",
    "#     plt.figure()\n",
    "    cv.imshow('What we see:', frame)\n",
    "#     print('Done')\n",
    "# plt.show()      \n",
    "       \n",
    "# Display the original frame\n",
    "# cv.imshow('What the Camera Sees:',frame)\n",
    "\n",
    "# Release the capture object\n",
    "close_camera()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-25T22:31:17.581759Z",
     "iopub.status.busy": "2021-03-25T22:31:17.581629Z",
     "iopub.status.idle": "2021-03-25T22:31:17.584654Z",
     "shell.execute_reply": "2021-03-25T22:31:17.583418Z",
     "shell.execute_reply.started": "2021-03-25T22:31:17.581746Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "close_camera()                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-19T09:52:40.639847Z",
     "iopub.status.busy": "2020-09-19T09:52:40.639632Z",
     "iopub.status.idle": "2020-09-19T09:52:40.642608Z",
     "shell.execute_reply": "2020-09-19T09:52:40.642059Z",
     "shell.execute_reply.started": "2020-09-19T09:52:40.639824Z"
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "# The rest of this file is for reference only.  \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "# Snippets\n",
    "\n",
    "```python\n",
    "# rotate the image\n",
    "frame = cv.rotate(frame, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-25T22:31:17.585261Z",
     "iopub.status.busy": "2021-03-25T22:31:17.585137Z",
     "iopub.status.idle": "2021-03-25T22:31:17.587131Z",
     "shell.execute_reply": "2021-03-25T22:31:17.586742Z",
     "shell.execute_reply.started": "2021-03-25T22:31:17.585248Z"
    }
   },
   "outputs": [],
   "source": [
    "# learn.export(f'../models/{RUN_NAME}.pkl')\n",
    "# path = Path('../models')\n",
    "# path.ls(file_exts='.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfodj",
   "language": "python",
   "name": "tfodj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
